{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "# Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project preprocessd data\n",
    "from package_folder import preprocessor_light_PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data, create X and Y, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yann/code/YannAll/automated_loan_review_project/raw_data/Loan_Default.csv\n"
     ]
    }
   ],
   "source": [
    "#Load raw data\n",
    "ROOT_PATH = pathlib.Path().resolve().parent # Get the parent directory of the current working directory\n",
    "raw_data_path = os.path.join(ROOT_PATH, 'raw_data', 'Loan_Default.csv')\n",
    "print(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148670, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'year', 'loan_limit', 'Gender', 'approv_in_adv', 'loan_type',\n",
       "       'loan_purpose', 'Credit_Worthiness', 'open_credit',\n",
       "       'business_or_commercial', 'loan_amount', 'rate_of_interest',\n",
       "       'Interest_rate_spread', 'Upfront_charges', 'term', 'Neg_ammortization',\n",
       "       'interest_only', 'lump_sum_payment', 'property_value',\n",
       "       'construction_type', 'occupancy_type', 'Secured_by', 'total_units',\n",
       "       'income', 'credit_type', 'Credit_Score', 'co-applicant_credit_type',\n",
       "       'age', 'submission_of_application', 'LTV', 'Region', 'Security_Type',\n",
       "       'Status', 'dtir1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = preprocessor_light_PCA.create_preprocessing_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data cleaned\n",
      "✅ Columns ['credit_type','year','ID','dtir1','Upfront_charges', 'LTV', 'Interest_rate_spread'] dropped\n",
      "✅ Missing values in categorical variables imputed\n",
      "✅ Categorical variables encoded successfully, including 'term'\n",
      "✅ Missing values imputed with Simple Imputer (mean), remaining NaNs filled with 0\n",
      "✅ Outliers removed based on IQR threshold\n",
      "✅ Continuous variables scaled and centered around 0\n"
     ]
    }
   ],
   "source": [
    "data_processed=full_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_processed.drop(columns='Status')\n",
    "y = data_processed[\"Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_column_names=list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (144218, 86) y shape: (144218,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_shape: {X.shape} y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m logistic_regression\u001b[38;5;241m.\u001b[39mpredict(X_test) \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the model accuracy\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m accuracy\u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(y_test, y_pred) \n\u001b[1;32m     12\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred) \n\u001b[1;32m     13\u001b[0m class_report \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the base model\n",
    "logistic_regression = LogisticRegression()\n",
    "#Create train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "# Train the model \n",
    "logistic_regression.fit(X_train, y_train)\n",
    "# Make predictions on the test set \n",
    "y_pred = logistic_regression.predict(X_test) \n",
    "# Evaluate the model accuracy\n",
    "accuracy= accuracy_score(y_test, y_pred) \n",
    "conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy score: {accuracy}\\n\")\n",
    "print(f\"Confusion matrix: {conf_matrix}\\n'\")\n",
    "print(f\"Class_report: {class_report}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and instantiate a PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "#Fit and transform X and display it as a dataframe\n",
    "pca.fit(X)\n",
    "X_proj=pca.transform(X)\n",
    "X_proj=pd.DataFrame(X_proj,columns=[f\"PC{i}\" for i in range(1,87)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display correlations after PCA treatment \n",
    "sns.heatmap(X_proj.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation: unlike expected, the correlations are not disappearing fully post PCA treatment. Let's investigate this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For now let's focus on reducing dimensionality\n",
    "pca.explained_variance_ratio_\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.title(\"Variance explained by PCA factors\")\n",
    "plt.xlabel('PCA')\n",
    "plt.ylabel('Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Put the % of variance explained in a dataframe\n",
    "percentage=[round(pca, 3) for pca in list(np.cumsum(pca.explained_variance_ratio_))]\n",
    "percentage=[float(pca) for pca in percentage]\n",
    "PCA_index=[i for i in range(1,87)]\n",
    "summary=pd.DataFrame(percentage,PCA_index,columns=['% of cumulated variance explained'])\n",
    "#Check how many PCA factors are requested to explain 95% of variance\n",
    "summary[summary['% of cumulated variance explained']<0.951]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion: 2=with only 24 PCA factors, we would still explain 95% of our initial X variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a PCA model to reduce dimensionality from currently 95 to 24 features\n",
    "pca_24=PCA(n_components=24)\n",
    "#Fit and transform X and display it as a dataframe\n",
    "pca_24.fit(X)\n",
    "X_proj_24=pca_24.transform(X)\n",
    "X_proj_24=pd.DataFrame(X_proj,columns=[f\"PC{i}\" for i in range(1,25)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Run a logistic regression on X_proj_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the base model\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_proj_24,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model \n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Make predictions on the test set \n",
    "y_pred = logistic_regression.predict(X_test) \n",
    "# Evaluate the model accuracy\n",
    "accuracy= accuracy_score(y_test, y_pred) \n",
    "conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "class_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy score: {accuracy}\\n\")\n",
    "print(f\"Confusion matrix: {conf_matrix}\\n'\")\n",
    "print(f\"Class_report: {class_report}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: the logistic regression recall drops from previously 29% to 25% when we add a PCA treatment to the preprocessing\n",
    "This is significant but logical given the 95% of variance kept post-PCA treatment.\n",
    "The main difference between preprocessing_light and preprocessing_light_PCA is actually not triggered by the PCA itself but by the scaler. PCA requires the data to be centered around 0 i.e. a standard scaler, while our preprocessing_light model worked with a MinMax scaler. It appears MinMax has a much better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train_pd=pd.DataFrame(X_train,columns=[f\"PC{i}\" for i in range(1,25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check correlation matrix of X_train\n",
    "sns.heatmap(X_train.corr(), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This time the correlation matrix is clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF THE NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
